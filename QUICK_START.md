# üöÄ Quick Start - Multi-Provider CLI Chat Plugin

Schnelleinstieg f√ºr die Verwendung von OpenAI und Gemini √ºber Claude Code.

---

## ‚ö° Installation (einmalig)

```bash
# 1. Commands installieren
/home/ralle/claude-code-multimodel/install-commands.sh

# 2. Shell-Integration aktivieren (optional, aber empfohlen)
/home/ralle/claude-code-multimodel/setup-shell-integration.sh
source ~/.bashrc

# 3. Neue Claude-Session starten
exit
claude
```

---

## üíª Verwendung

### OpenAI Commands

#### Beste Qualit√§t (komplexe Aufgaben)
```bash
/openai-cli {
  "prompt": "Entwirf eine skalierbare Microservices-Architektur f√ºr ein E-Commerce-System",
  "model": "gpt-5.1-codex",
  "sandbox": "danger-full-access",
  "approval_policy": "never"
}
```

#### Schnelle Code-Generierung
```bash
/openai-cli {
  "prompt": "Schreibe eine Python-Funktion f√ºr Quicksort mit Unit-Tests",
  "model": "gpt-5.1-codex-mini"
}
```

#### Allgemeine Fragen
```bash
/openai-cli {
  "prompt": "Erkl√§re mir den Unterschied zwischen REST und GraphQL",
  "model": "gpt-5.1"
}
```

---

### Gemini Commands

#### H√∂chste Intelligenz (1M Token Context)
```bash
/gemini-cli {
  "prompt": "Analysiere diese gesamte Codebase und gib mir eine detaillierte Architektur-Bewertung",
  "model": "gemini-3-pro-preview-11-2025",
  "approval_mode": "yolo"
}
```

#### Mit sichtbarem Reasoning
```bash
/gemini-cli {
  "prompt": "L√∂se dieses komplexe Dynamic Programming Problem und zeige mir deinen Denkprozess Schritt f√ºr Schritt",
  "model": "gemini-3-pro-preview-11-2025-thinking"
}
```

#### Ultra-schnelle Antworten
```bash
/gemini-cli {
  "prompt": "Quick: Was ist der Big-O von Binary Search?",
  "model": "gemini-3.0-flash",
  "yolo": true
}
```

---

## üéØ Modell-Empfehlungen

### F√ºr Coding

| Anforderung | OpenAI | Gemini |
|-------------|--------|--------|
| **Beste Qualit√§t** | `gpt-5.1-codex` | `gemini-3-pro-preview-11-2025` |
| **Beste Speed** | `gpt-5.1-codex-mini` | `gemini-3.0-flash` |
| **Gro√üe Codebases** | - | `gemini-3-pro-preview-11-2025` (1M context) |
| **Debugging** | `gpt-5.1-codex-mini` | `gemini-3-pro-preview-11-2025-thinking` |

### F√ºr Allgemein

| Anforderung | OpenAI | Gemini |
|-------------|--------|--------|
| **Balanced** | `gpt-5.1` | `gemini-2.5-pro` |
| **H√∂chste Intelligenz** | `gpt-5.1-codex` | `gemini-3-pro-preview-11-2025` |
| **Schnellste Antworten** | `gpt-5.1-codex-mini` | `gemini-3.0-flash` |

---

## üîê Authentifizierung

### OpenAI (einmalig)
```bash
codex login
```

### Gemini (einmalig)
```bash
# Folge dem Login-Flow der Gemini CLI
gemini --help
```

---

## üõ†Ô∏è Hilfsbefehle (Shell-Aliase)

Nach Installation der Shell-Integration:

```bash
# Commands pr√ºfen
claude-commands-verify

# Commands neu installieren
claude-commands-install

# Gesamtes Plugin-Setup pr√ºfen
claude-plugins-check
```

---

## ‚ùì H√§ufige Fragen

### Commands nicht verf√ºgbar?
```bash
# 1. Pr√ºfen
ls -la ~/.claude/commands/

# 2. Falls leer
claude-commands-install

# 3. Neue Claude-Session starten
exit && claude
```

### "Error: not logged in"?
```bash
# OpenAI
codex login

# Gemini
gemini  # Folge Login-Anweisungen
```

### "Rate limit reached"?
Nutze den anderen Provider:
- OpenAI limit ‚Üí Nutze Gemini
- Gemini limit ‚Üí Nutze OpenAI

---

## üìö Weitere Dokumentation

- **Vollst√§ndige Modell-Info**: `MODEL_UPDATES_2025.md`
- **Persistenz-Guide**: `PERSISTENCE_GUIDE.md`
- **Troubleshooting**: `PLUGIN_TROUBLESHOOTING.md`
- **Plugin README**: `plugins/multi-provider-cli-chat/README.md`

---

## üéâ Beispiel-Session

```bash
# Starte Claude
claude

# Frage Claude etwas
"Kannst du mir helfen, eine REST API zu designen?"

# Cross-Check mit OpenAI
/openai-cli {
  "prompt": "Designvorschl√§ge f√ºr eine REST API mit User-Management",
  "model": "gpt-5.1-codex"
}

# Cross-Check mit Gemini
/gemini-cli {
  "prompt": "Was sind die Best Practices f√ºr REST API Design?",
  "model": "gemini-3-pro-preview-11-2025"
}

# Vergleiche alle drei Antworten
```

---

*Viel Erfolg! üöÄ*
